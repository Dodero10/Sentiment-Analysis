{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02ca3b46f45f2b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ABSA_Dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        tokens, tags, pols = self.df.iloc[idx, :3].values\n",
    "        \n",
    "        tokens = tokens.replace(\"'\", \"\").strip(\"][\").split(', ')\n",
    "        tags = tags.strip('][').split(', ')\n",
    "        pols = pols.strip('][').split(', ')\n",
    "        \n",
    "        bert_tokens = []\n",
    "        bert_tags = []\n",
    "        bert_pols = []\n",
    "        \n",
    "        for i in range(len(tokens)):\n",
    "            t = self.tokenizer.tokenize(tokens[i])\n",
    "            bert_tokens += t\n",
    "            bert_tags += [int(tags[i])]*len(t)\n",
    "            bert_pols += [int(pols[i])]*len(t)\n",
    "            \n",
    "        bert_ids = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "        \n",
    "        ids_tensor = torch.tensor(bert_ids)\n",
    "        tags_tensor = torch.tensor(bert_tags)\n",
    "        pols_tensor = torch.tensor(bert_pols)\n",
    "        return bert_tokens, ids_tensor, tags_tensor, pols_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "train_df = pd.read_csv('./data/en/restaurants_train.csv')\n",
    "test_df = pd.read_csv('./data/en/restaurants_test.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51831ac0e43eebbc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "996e8c0e940839ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e4cb8558c03f2ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31e22b4f45b4765"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenizer.cls_token_id"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15dc5b0501b88122"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_ds = ABSA_Dataset(train_df, tokenizer)\n",
    "test_ds = ABSA_Dataset(test_df, tokenizer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4478b2743bc4f71d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(train_ds)\n",
    "len(test_ds)\n",
    "next(iter(train_ds))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d024b81160264558"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def padding(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True)\n",
    "\n",
    "    tags_tensors = [s[2] for s in samples]\n",
    "    tags_tensors = pad_sequence(tags_tensors, batch_first=True)\n",
    "\n",
    "    pols_tensors = [s[3] for s in samples]\n",
    "    pols_tensors = pad_sequence(pols_tensors, batch_first=True)\n",
    "\n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "\n",
    "    return ids_tensors, tags_tensors, pols_tensors, masks_tensors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65a0172a7293d76b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=padding)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=padding)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "669361b0fe2e9141"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "799b2466cbb39389"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfd376984d3b79e2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class ABTE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ABTE, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, 3)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, ids_tensors, masks_tensors, tags_tensors):\n",
    "        bert_outputs = self.bert(\n",
    "            input_ids=ids_tensors,\n",
    "            attention_mask=masks_tensors,\n",
    "            return_dict=False\n",
    "        )\n",
    "        bert_outputs = bert_outputs[0]\n",
    "        linear_outputs = self.linear(bert_outputs)\n",
    "        if tags_tensors is not None:\n",
    "            tags_tensors = tags_tensors.view(-1)\n",
    "            linear_outputs_ = linear_outputs.view(-1, 3)\n",
    "            loss = self.loss_fn(linear_outputs_, tags_tensors)\n",
    "            return loss, linear_outputs\n",
    "        else:\n",
    "            return linear_outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb45b89e84fab70d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = ABTE(model_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49f74079c1f713cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "250b683e368476bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6e97e32165f7eac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f67f34eb9a338aed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_epoch(model, optimizer, train_loader, device):\n",
    "    losses = []\n",
    "    for batch in (train_loader):\n",
    "        ids_tensors, tags_tensors, _, masks_tensors = batch\n",
    "        ids_tensors = ids_tensors.to(device)\n",
    "        tags_tensors = tags_tensors.to(device)\n",
    "        masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "        loss, _ = model(\n",
    "            ids_tensors=ids_tensors,\n",
    "            masks_tensors=masks_tensors,\n",
    "            tags_tensors=tags_tensors\n",
    "        )\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return sum(losses)/len(losses)\n",
    "\n",
    "def evaluate_epoch(model, valid_loader, device):\n",
    "    losses = []\n",
    "\n",
    "    preds, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in (valid_loader):\n",
    "            ids_tensors, tags_tensors, _, masks_tensors = batch\n",
    "            ids_tensors = ids_tensors.to(device)\n",
    "            tags_tensors = tags_tensors.to(device)\n",
    "            masks_tensors = masks_tensors.to(device)\n",
    "\n",
    "            loss, outputs = model(\n",
    "                ids_tensors=ids_tensors,\n",
    "                masks_tensors=masks_tensors,\n",
    "                tags_tensors=tags_tensors\n",
    "            )\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, p = torch.max(outputs, dim=2)\n",
    "            preds += list([int(j) for i in p for j in i ])\n",
    "            labels += list([int(j) for i in tags_tensors for j in i ])\n",
    "\n",
    "    acc = np.mean(np.array(preds) == np.array(labels))\n",
    "    return sum(losses)/len(losses), acc\n",
    "\n",
    "train_losses = []\n",
    "eval_accs, eval_losses = [], []\n",
    "\n",
    "def train(model, model_name, save_model, optimizer, train_loader, valid_loader, num_epochs, device):\n",
    "    best_loss_eval = 100\n",
    "    times = []\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        # Training\n",
    "        train_loss = train_epoch(model, optimizer, train_loader, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluation\n",
    "        eval_loss, eval_acc = evaluate_epoch(model, valid_loader, device)\n",
    "        eval_accs.append(eval_acc)\n",
    "        eval_losses.append(eval_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if eval_loss < best_loss_eval:\n",
    "            torch.save(model.state_dict(), save_model + f'/{model_name}.pt')\n",
    "\n",
    "        times.append(time.time() - epoch_start_time)\n",
    "        # Print loss, acc end epoch\n",
    "        print(\"-\" * 59)\n",
    "        print(\n",
    "            \"| End of epoch {:3d} | Time: {:5.2f}s | Train Loss {:8.3f} \"\n",
    "            \"| Valid Accuracy {:8.3f} | Valid Loss {:8.3f} \".format(\n",
    "                epoch, time.time() - epoch_start_time, train_loss, eval_acc, eval_loss\n",
    "            )\n",
    "        )\n",
    "        print(\"-\" * 59)\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_model + f'/{model_name}.pt'))\n",
    "    model.eval()\n",
    "    metrics = {\n",
    "        'train_loss': train_losses,\n",
    "        'valid_accuracy': eval_accs,\n",
    "        'valid_loss': eval_losses,\n",
    "        'time': times\n",
    "    }\n",
    "    return model, metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24b17364173697e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!mkdir \"./model\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbb39beecc517f46"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "save_model = \"./model\"\n",
    "model = ABTE(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 50\n",
    "best_model, metrics = train(\n",
    "    model, model_name, save_model, optimizer, train_loader, test_loader, num_epochs, device\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4436112fb91630f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(train_losses, eval_losses, eval_accs, num_epochs):\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "\n",
    "    # Create a figure for losses\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plotting training and validation losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, eval_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, eval_accs, color='green', label='Validation Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the training history\n",
    "plot_training_history(train_losses, eval_losses, eval_accs, num_epochs)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e482b9d155b2b8b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecd66b0ad7d54314"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(best_model, sentence, device):\n",
    "    word_pieces = list(tokenizer.tokenize(sentence))\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([input_ids]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor, None, None)\n",
    "        _, predictions = torch.max(outputs, dim=2)\n",
    "\n",
    "    predictions = predictions[0].tolist()\n",
    "    return word_pieces, predictions, outputs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a15cde5f96887a68"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sentence = \" \".join(test_df.iloc[0][\"Tokens\"].replace(\"'\", \"\").strip(\"][\").split(', '))\n",
    "predict(best_model, sentence, device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38a0530f5c9a2051"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
